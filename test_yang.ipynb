{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autovc.speaker_encoder.utils import *\n",
    "import soundfile as sf\n",
    "from autovc.utils.hparams import SpeakerEncoderParams as params\n",
    "from autovc.utils.preprocess_wav import audio_to_melspectrogram\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = [w for w in os.walk(\"data/yang_test\")][0]\n",
    "root, dirs, files = [w for w in walk]\n",
    "\n",
    "for file in files:\n",
    "    waveform = preprocess_wav(os.path.join(root, file))\n",
    "    sf.write(f\"test_yang_silence/{file}\", np.asarray(waveform), samplerate = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk = [w for w in os.walk(\"test_yang_silence\")][0]\n",
    "_, _, files = [w for w in walk]\n",
    "\n",
    "specs_org = []\n",
    "specs_new = []\n",
    "\n",
    "for file in files:\n",
    "    specs_org.append(audio_to_melspectrogram(os.path.join(\"data/yang_test\", file)))\n",
    "    specs_new.append(audio_to_melspectrogram(os.path.join(\"test_yang_silence\", file)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_new = np.array([np.shape(s)[1] for s in specs_new])\n",
    "lens_org = np.array([np.shape(s)[1] for s in specs_org])\n",
    "\n",
    "\n",
    "# (lens_org-lens_new)/lens_org\n",
    "lens_new.std()\n",
    "lens_new.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s183920\\AppData\\Local\\Temp/ipykernel_1208/3162794849.py:37: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  audio_mask = np.round(audio_mask).astype(np.bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = params()\n",
    "\n",
    "def chop(wav):\n",
    "    \"\"\"\n",
    "    Ensures that segments without voice in the waveform remain no longer than a \n",
    "    threshold determined by the VAD parameters in params.py.\n",
    "\n",
    "    :param wav: the raw waveform as a numpy array of floats \n",
    "    :return: the same waveform with silences trimmed away (length <= original wav length)\n",
    "    \"\"\"\n",
    "    # Compute the voice detection window size\n",
    "    samples_per_window = (hparams.vad_window_length * hparams.sampling_rate) // 1000\n",
    "    \n",
    "    # Trim the end of the audio to have a multiple of the window size\n",
    "    wav = wav[:len(wav) - (len(wav) % samples_per_window)]\n",
    "    \n",
    "    # Convert the float waveform to 16-bit mono PCM\n",
    "    pcm_wave = struct.pack(\"%dh\" % len(wav), *(np.round(wav * int16_max)).astype(np.int16))\n",
    "    \n",
    "    # Perform voice activation detection\n",
    "    voice_flags = []\n",
    "    vad = webrtcvad.Vad(mode=3)\n",
    "    for window_start in range(0, len(wav), samples_per_window):\n",
    "        window_end = window_start + samples_per_window\n",
    "        voice_flags.append(vad.is_speech(pcm_wave[window_start * 2:window_end * 2],\n",
    "                                         sample_rate=hparams.sampling_rate))\n",
    "    voice_flags = np.array(voice_flags)\n",
    "    \n",
    "    # Smooth the voice detection with a moving average\n",
    "    def moving_average(array, width):\n",
    "        array_padded = np.concatenate((np.zeros((width - 1) // 2), array, np.zeros(width // 2)))\n",
    "        ret = np.cumsum(array_padded, dtype=float)\n",
    "        ret[width:] = ret[width:] - ret[:-width]\n",
    "        return ret[width - 1:] / width\n",
    "    \n",
    "    audio_mask = moving_average(voice_flags, hparams.vad_moving_average_width)\n",
    "    audio_mask = np.round(audio_mask).astype(np.bool)\n",
    "    \n",
    "    # Dilate the voiced regions\n",
    "    audio_mask = binary_dilation(audio_mask, np.ones(hparams.vad_max_silence_length + 1))\n",
    "    audio_mask = np.repeat(audio_mask, samples_per_window)\n",
    "    \n",
    "    # return wav[audio_mask == True]\n",
    "    return audio_mask\n",
    "\n",
    "wav, source_sr = librosa.load(\"data/yang_test/aaa_z0030_011.wav\", sr=None)\n",
    "chop(wav)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2d64eaaf381fd06d7f37ec58cef8effe3342c0f8da6340727723fa2e10bc046"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
